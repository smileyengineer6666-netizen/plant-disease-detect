# ğŸ—ï¸ SYSTEM ARCHITECTURE

## Overview

This system implements a complete CNN â†’ LLM pipeline for plant disease detection and treatment recommendation.

---

## Component Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INTERFACES                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Streamlit UI   â”‚   CLI Tool       â”‚  Python API      â”‚         â”‚
â”‚   (app.py)      â”‚   (cli.py)       â”‚  (pipeline.py)   â”‚  Mobile â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   PlantDiseaseAssistant (Pipeline)  â”‚
         â”‚       (plant_disease_pipeline.py)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   CNN Model     â”‚  â”‚   LLM Client    â”‚
         â”‚  MobileNetV2    â”‚  â”‚     Ollama      â”‚
         â”‚  (cnn.py)       â”‚  â”‚    (llm.py)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ PyTorch Model   â”‚  â”‚  Ollama Server  â”‚
         â”‚  (3.5M params)  â”‚  â”‚  (localhost)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow

### 1. Image Input â†’ CNN Detection

```
Leaf Image (any size)
    â”‚
    â”œâ”€â–º Resize to 256Ã—256
    â”œâ”€â–º Center crop to 224Ã—224
    â”œâ”€â–º Normalize (ImageNet stats)
    â””â”€â–º Convert to Tensor [1, 3, 224, 224]
         â”‚
         â–¼
    MobileNetV2 (frozen backbone)
         â”‚
         â”œâ”€â–º Feature extraction (1280 features)
         â””â”€â–º Classifier (trainable)
              â”‚
              â–¼
         Softmax output [N classes]
              â”‚
              â”œâ”€â–º argmax â†’ Predicted class
              â”œâ”€â–º max â†’ Confidence score
              â””â”€â–º all values â†’ Probability distribution
                   â”‚
                   â–¼
         {
           "plant": "Tomato",
           "disease": "Early blight",
           "confidence": 0.92,
           "is_confident": true,
           "top_5": [...]
         }
```

### 2. CNN Output â†’ LLM Prompt

```
Detection Result
    â”‚
    â”œâ”€â–º Extract: plant, disease, confidence
    â”œâ”€â–º Check: is_confident (threshold)
    â””â”€â–º Generate structured prompt
         â”‚
         â–¼
    If CONFIDENT:
    "You are an expert... Plant: Tomato, Disease: Early blight,
     Confidence: 92%. Provide: Overview, Symptoms, Actions,
     Treatment, Prevention..."
    
    If UNCERTAIN:
    "Low confidence (65%). Explain why, what to look for,
     general precautions, when to seek help..."
         â”‚
         â–¼
    Send to Ollama API
```

### 3. LLM Response â†’ User

```
Ollama LLM (llama3.2:3b)
    â”‚
    â”œâ”€â–º Process prompt with context
    â”œâ”€â–º Generate treatment advice
    â””â”€â–º Return formatted text
         â”‚
         â–¼
    {
      "advice": "Disease Overview: Early blight...",
      "success": true,
      "model_used": "llama3.2:3b"
    }
         â”‚
         â–¼
    Display to user via UI/CLI
```

---

## Model Architecture Details

### MobileNetV2 Structure

```
Input: [batch, 3, 224, 224]
    â”‚
    â”œâ”€â–º Conv2d (32 channels)
    â”œâ”€â–º Inverted Residuals (frozen) â—„â”€â”€â”€ 17 bottleneck blocks
    â”œâ”€â–º Conv2d (1280 features)
    â”‚
    â””â”€â–º Classifier (trainable):
         â”œâ”€â–º Dropout(0.2)
         â””â”€â–º Linear(1280 â†’ N classes)
              â”‚
              â–¼
Output: [batch, N]  (logits)
```

**Parameters:**
- Total: ~3.5M
- Trainable: ~1.2M (classifier only)
- Frozen: ~2.3M (backbone)

**Why MobileNetV2?**
- âœ… Lightweight (200MB RAM)
- âœ… Fast inference (50ms CPU, 5ms GPU)
- âœ… Mobile-friendly
- âœ… Transfer learning efficient
- âœ… Proven for image classification

---

## Training Strategy

```
Dataset (ImageFolder format)
    â”‚
    â”œâ”€â–º train/ (80%)
    â”‚    â”œâ”€â–º Apple___Apple_scab/
    â”‚    â”œâ”€â–º Tomato___Early_blight/
    â”‚    â””â”€â–º ...
    â”‚
    â””â”€â–º val/ (20%)
         â”œâ”€â–º Apple___Apple_scab/
         â””â”€â–º ...
              â”‚
              â–¼
    Load pretrained MobileNetV2 (ImageNet weights)
              â”‚
              â”œâ”€â–º Freeze all backbone layers
              â””â”€â–º Replace final classifier
                   â”‚
                   â–¼
    Train ONLY classifier (1.2M params)
              â”‚
              â”œâ”€â–º Optimizer: Adam (lr=0.001)
              â”œâ”€â–º Loss: CrossEntropyLoss
              â”œâ”€â–º Scheduler: ReduceLROnPlateau
              â”œâ”€â–º Augmentation: Flip, Rotate, ColorJitter
              â””â”€â–º Epochs: 10-20
                   â”‚
                   â–¼
    Save best model (highest val accuracy)
```

**Why Transfer Learning?**
- âœ… Faster training (10 epochs vs 100+)
- âœ… Less data needed (100s vs 1000s per class)
- âœ… Better generalization
- âœ… Lower compute requirements

---

## LLM Integration

### Ollama Architecture

```
User Query
    â”‚
    â–¼
Local Ollama Server (localhost:11434)
    â”‚
    â”œâ”€â–º Model: llama3.2:3b (3GB RAM)
    â”œâ”€â–º Context: 8K tokens
    â””â”€â–º Temperature: 0.3 (focused)
         â”‚
         â–¼
    Generate response
         â”‚
         â”œâ”€â–º Structured advice
         â”œâ”€â–º Farmer-friendly language
         â””â”€â–º Actionable steps
              â”‚
              â–¼
    Return JSON response
```

**Why Ollama?**
- âœ… Fully local (privacy)
- âœ… No API costs
- âœ… Offline capable
- âœ… Easy model switching
- âœ… Fast inference

**Fallback Strategy:**
```
Try Ollama
    â”‚
    â”œâ”€â–º Success? â†’ Use LLM advice
    â”‚
    â””â”€â–º Failed? â†’ Use rule-based fallback
         â”‚
         â”œâ”€â–º Check if healthy/diseased
         â”œâ”€â–º Provide basic recommendations
         â””â”€â–º Suggest consulting expert
```

---

## File Organization

```
plant-disease-detection/
â”‚
â”œâ”€â”€ Core Components
â”‚   â”œâ”€â”€ plant_disease_cnn.py       # CNN model (MobileNetV2)
â”‚   â”œâ”€â”€ plant_disease_llm.py       # LLM client (Ollama)
â”‚   â””â”€â”€ plant_disease_pipeline.py  # Complete pipeline
â”‚
â”œâ”€â”€ Interfaces
â”‚   â”œâ”€â”€ app.py                      # Streamlit web UI
â”‚   â””â”€â”€ cli.py                      # Command-line tool
â”‚
â”œâ”€â”€ Training & Testing
â”‚   â”œâ”€â”€ train.py                    # Model training script
â”‚   â””â”€â”€ test_system.py              # Installation tester
â”‚
â”œâ”€â”€ Documentation
â”‚   â”œâ”€â”€ README.md                   # Full documentation
â”‚   â”œâ”€â”€ SETUP.md                    # Quick setup guide
â”‚   â””â”€â”€ ARCHITECTURE.md             # This file
â”‚
â””â”€â”€ Configuration
    â””â”€â”€ requirements.txt            # Python dependencies
```

---

## Deployment Options

### Option 1: Local Development
```
Python 3.8+
    â”œâ”€â–º Install dependencies
    â”œâ”€â–º Run Ollama locally
    â””â”€â–º Start Streamlit/CLI
```

### Option 2: Cloud Deployment
```
Server (2GB RAM minimum)
    â”œâ”€â–º Install PyTorch (CPU)
    â”œâ”€â–º Install Ollama
    â”œâ”€â–º Deploy as web service
    â””â”€â–º nginx â†’ Streamlit
```

### Option 3: Mobile App (Future)
```
React Native
    â”œâ”€â–º Export model to ONNX/CoreML
    â”œâ”€â–º On-device inference
    â””â”€â–º Cloud LLM (optional)
```

### Option 4: API Service
```
FastAPI Backend
    â”œâ”€â–º /predict endpoint (CNN)
    â”œâ”€â–º /advice endpoint (LLM)
    â””â”€â–º /analyze endpoint (full pipeline)
```

---

## Performance Characteristics

### CNN Inference
- **CPU:** ~50ms per image
- **GPU:** ~5ms per image
- **Memory:** 200MB RAM
- **Batch:** ~100 images/sec (GPU)

### LLM Generation
- **Latency:** 2-5 seconds
- **Memory:** 3GB RAM (llama3.2:3b)
- **Throughput:** ~30 tokens/sec
- **Context:** 8K tokens

### Complete Pipeline
- **Total time:** 3-6 seconds
- **Memory:** 3.5GB total
- **Concurrent:** 5-10 users (8GB RAM)

---

## Scalability Considerations

### Horizontal Scaling
```
Load Balancer
    â”‚
    â”œâ”€â–º CNN Server 1 (GPU)
    â”œâ”€â–º CNN Server 2 (GPU)
    â”œâ”€â–º CNN Server 3 (GPU)
    â”‚
    â””â”€â–º Ollama Cluster
         â”œâ”€â–º LLM Instance 1
         â”œâ”€â–º LLM Instance 2
         â””â”€â–º LLM Instance 3
```

### Optimization Strategies
1. **CNN:**
   - Model quantization (INT8)
   - TensorRT/ONNX Runtime
   - Batch processing
   - Model distillation

2. **LLM:**
   - Response caching
   - Smaller models (1B params)
   - Prompt optimization
   - Async processing

3. **Infrastructure:**
   - CDN for static assets
   - Redis for caching
   - Queue system (Celery)
   - Database for results

---

## Security & Privacy

### Data Handling
```
User Image
    â”‚
    â”œâ”€â–º Process in memory (no storage)
    â”œâ”€â–º Delete after analysis
    â””â”€â–º No personally identifiable info
```

### Local-First Design
- CNN runs locally (PyTorch)
- LLM runs locally (Ollama)
- No external API calls
- No data transmission
- Full privacy guarantee

### Production Considerations
- HTTPS for web deployment
- Input validation (file size, type)
- Rate limiting
- Error handling
- Logging (no sensitive data)

---

## Future Enhancements

### Technical
- [ ] Explainable AI (Grad-CAM visualizations)
- [ ] Multi-disease detection
- [ ] Severity scoring
- [ ] Temporal tracking
- [ ] Weather integration

### Features
- [ ] Multilingual support (10+ languages)
- [ ] Voice input/output
- [ ] Mobile app
- [ ] Offline mode (fully cached)
- [ ] Community database

### Models
- [ ] EfficientNet-B0 (better accuracy)
- [ ] Custom lightweight model
- [ ] Ensemble predictions
- [ ] Active learning

---

## References

**CNN Architecture:**
- MobileNetV2: https://arxiv.org/abs/1801.04381
- Transfer Learning: https://cs231n.github.io/transfer-learning/

**LLM:**
- Ollama: https://ollama.com
- Llama 3.2: https://ai.meta.com/llama/

**Frameworks:**
- PyTorch: https://pytorch.org
- Streamlit: https://streamlit.io

---

**Last Updated:** 2024
**Version:** 1.0
**Author:** Your Name
